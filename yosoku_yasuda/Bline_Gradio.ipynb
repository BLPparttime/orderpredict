{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad1b870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasudayuuya/orderpredict/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/_sk4lq9107v79smv_pqvls780000gn/T/ipykernel_76122/596951432.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n",
      "/var/folders/wl/_sk4lq9107v79smv_pqvls780000gn/T/ipykernel_76122/596951432.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n",
      "/var/folders/wl/_sk4lq9107v79smv_pqvls780000gn/T/ipykernel_76122/596951432.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n",
      "/var/folders/wl/_sk4lq9107v79smv_pqvls780000gn/T/ipykernel_76122/596951432.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n",
      "/var/folders/wl/_sk4lq9107v79smv_pqvls780000gn/T/ipykernel_76122/596951432.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n",
      "/var/folders/wl/_sk4lq9107v79smv_pqvls780000gn/T/ipykernel_76122/596951432.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "MODEL_PATH = \"models/gbm_model.pkl\"  \n",
    "\n",
    "def process_and_predict(file2, file3):\n",
    "    sheet_name = \"実績昼\"\n",
    "    def clean_data(file_path, sheet_name):\n",
    "\n",
    "        # データ読み込み\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "        # 転置\n",
    "        df = df.T\n",
    "\n",
    "        # 1行目をカラム名にして削除\n",
    "        df.columns = df.iloc[1]\n",
    "        df = df.drop(df.index[[0, 1]])\n",
    "\n",
    "        # 「項目」列がある2列目以降を抽出（1列目は\"作業ライン\"、2列目が\"項目\"）\n",
    "        df_section = df.iloc[1:10, 1:21]  # 2行目〜10行目、2列目〜21列目（日付1〜20）\n",
    "\n",
    "        # 最初の列をインデックス（項目名）として、列を日付とするように転置\n",
    "        df_section.columns = df_section.iloc[0]  # 2行目（\"件数\"など）をカラム名にする\n",
    "        df_section = df_section.drop(df_section.index[0])  # カラム名に使った行を削除\n",
    "\n",
    "        # 行番号を日付（1〜20）にして分かりやすく\n",
    "        df_section = df_section.reset_index(drop=True)\n",
    "        df_section.insert(0, \"日付\", range(1, len(df_section) + 1))\n",
    "\n",
    "\n",
    "        # 削除対象のカラム名\n",
    "        columns_to_drop = [\n",
    "            np.nan,\n",
    "            'テイケイ',\n",
    "            '目標件数',\n",
    "            '予測',\n",
    "            '1本あたりの平均作業数',\n",
    "            '1本あたりの平均作業', \n",
    "            '1日あたりの作業件数',\n",
    "            '買い合わせ平均',      \n",
    "            '項目',\n",
    "            '生産性(分/件)',\n",
    "            '1日作業量/L'\n",
    "        ]\n",
    "\n",
    "        # 一致するカラムのみ削除\n",
    "        df = df.drop(columns=[col for col in df.columns if col in columns_to_drop])\n",
    "\n",
    "        # 欠損値を0で埋める\n",
    "        df = df.fillna(0)\n",
    "\n",
    "        # 34行目（インデックス33）を削除\n",
    "        df.drop(df.index[[31]])\n",
    "\n",
    "        # 「件数」が0の行を削除（数値変換してから）\n",
    "        if '1人あたりの作業時間' in df.columns:\n",
    "            df['1人あたりの作業時間'] = pd.to_numeric(df['1人あたりの作業時間'], errors='coerce').fillna(0)\n",
    "            df = df[df['1人あたりの作業時間'] != 0]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    df2 = clean_data(file2, sheet_name )\n",
    "    df3 = clean_data(file3, sheet_name)\n",
    "\n",
    "    # 対数変換\n",
    "    df2 = df2.apply(lambda x: np.log(x + 1))\n",
    "    df3 = df3.apply(lambda x: np.log(x + 1))\n",
    "\n",
    "    # カラム順合わせ\n",
    "    df2 = df2[df3.columns]\n",
    "\n",
    "    # 学習・予測用データ\n",
    "    X_train = df2.drop(columns='件数')\n",
    "    y_train = df2['件数']\n",
    "    X_test = df3.drop(columns='件数')\n",
    "    y_test = df3['件数']\n",
    "\n",
    "    # ベイズ最適化\n",
    "    def optimize_model(n_estimators, learning_rate, max_depth, max_features, min_samples_split, subsample):\n",
    "        model = GradientBoostingRegressor(\n",
    "            n_estimators=int(n_estimators),\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=int(max_depth),\n",
    "            max_features=max_features,\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            subsample=subsample,\n",
    "            random_state=42\n",
    "        )\n",
    "        return cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "    pbounds = {\n",
    "        'n_estimators': (100, 1000),\n",
    "        'learning_rate': (0.005, 0.3),\n",
    "        'max_depth': (3, 15),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'subsample': (0.5, 1.0),\n",
    "        'max_features': (0.5, 1.0)\n",
    "    }\n",
    "\n",
    "    optimizer = BayesianOptimization(f=optimize_model, pbounds=pbounds, random_state=42, verbose=0)\n",
    "    optimizer.maximize(init_points=5, n_iter=20)\n",
    "    best_params = optimizer.max['params']\n",
    "    best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "    best_params['max_depth'] = int(best_params['max_depth'])\n",
    "    best_params['min_samples_split'] = int(best_params['min_samples_split'])\n",
    "\n",
    "    model = GradientBoostingRegressor(**best_params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 予測と元スケールへの逆変換\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_original = np.exp(y_pred)\n",
    "    y_test_original = np.exp(y_test)\n",
    "\n",
    "    # 'Unnamed:' を削除し、数値を-1する\n",
    "    modified_index = [int(item.replace('Unnamed: ', '')) - 1 for item in df3.index]\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"日付\": modified_index,\n",
    "        \"予測件数\": y_pred_original,\n",
    "        \"実績件数\": y_test_original.values,\n",
    "        \"差分（予測件数ー実績件数）\": y_pred_original - y_test_original.values\n",
    "    })\n",
    "    # ① to_html でクラス名を付与して HTML テーブル文字列を生成\n",
    "    html_table = result_df.to_html(\n",
    "        classes=\"result-table\", \n",
    "        index=False, \n",
    "        border=1\n",
    "    )\n",
    "\n",
    "    r2 = r2_score(y_test_original, y_pred_original)\n",
    "    summary = f\"R²スコア: {r2:.3f}（1に近いほど良好）\"\n",
    "\n",
    "    return summary, html_table\n",
    "\n",
    "# --- CSS を定義 ---\n",
    "custom_css = \"\"\"\n",
    ".result-table {\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    ".result-table th,\n",
    ".result-table td {\n",
    "  border: 1px solid #ddd;\n",
    "  padding: 8px;\n",
    "  text-align: center;\n",
    "}\n",
    "/* 「予測件数」列だけ赤文字に */\n",
    ".result-table td:nth-child(2),\n",
    ".result-table th:nth-child(2) {\n",
    "  color: red;\n",
    "  font-weight: bold;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# --- Gradio UI ---\n",
    "with gr.Blocks(css=custom_css) as demo:\n",
    "    gr.Markdown(\"## 平和島LBの作業件数予測\")\n",
    "    gr.Markdown(\"過去実績をもとに出荷月の作業件数を予測します\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            inp1 = gr.File(label=\"2月のExcelファイル（件数あり）\")\n",
    "            inp2 = gr.File(label=\"出荷月のExcelファイル\")\n",
    "            btn = gr.Button(\"予測実行\")\n",
    "        with gr.Column():\n",
    "            out1 = gr.Text(label=\"予測モデルの性能\")\n",
    "            out2 = gr.HTML(label=\"各日の予測 vs 実績（件数）\")\n",
    "    btn.click(\n",
    "        fn=process_and_predict,\n",
    "        inputs=[inp1, inp2],\n",
    "        outputs=[out1, out2],\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
